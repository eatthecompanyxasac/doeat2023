{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import requests\n",
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 맞춤법 교정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- py-hanspell 설치 후 진행\n",
    "- 파이썬 버전 3.10이상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kurly = pd.read_csv('C:/Users/NT550-048/Desktop/잇더/data/data_kurly_sentiment.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kurly['ReviewText'] = data_kurly['ReviewText'].apply(lambda x:x.replace('&', ',') if '&' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kurly['fixed_ReviewText'] = data_kurly['ReviewText'].apply(lambda x:spell_checker.check(x).checked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500자이상 리뷰 처리\n",
    "- 500자 이상은 hanspell 불가\n",
    "- 500자 이상 리뷰 문장별로 나눠서 맞춤법 교정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kss import split_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 1083\n",
      "ERROR: 1198\n",
      "ERROR: 3263\n",
      "ERROR: 5034\n",
      "ERROR: 5533\n",
      "ERROR: 8168\n",
      "ERROR: 8522\n",
      "ERROR: 10039\n",
      "ERROR: 10253\n",
      "ERROR: 10290\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for i in range(len(data_kurly)):\n",
    "    try:\n",
    "        tokens.append(get_pos(data_kurly['fixed_ReviewText'][i]))\n",
    "    except:\n",
    "        print('ERROR:',i)\n",
    "        tokens.append('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NT550-048\\AppData\\Local\\Temp\\ipykernel_13372\\482859583.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_kurly['fixed_ReviewText'][n] = '. '.join(longreview_checked)\n"
     ]
    }
   ],
   "source": [
    "# 500자 이상 리뷰는 hanspell 실행 불가\n",
    "# 문장별로 쪼개서 hanspell 수행\n",
    "nums = [1083, 1198, 3263, 5034, 5533, 8168, 8522, 10039, 10253, 10290]\n",
    "for n in nums:\n",
    "    temp_longreview_list = split_sentences(data_kurly['ReviewText'][n])\n",
    "    longreview_checked = []\n",
    "    for txt in temp_longreview_list:\n",
    "        longreview_checked.append(spell_checker.check(txt).checked)\n",
    "    data_kurly['fixed_ReviewText'][n] = '. '.join(longreview_checked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 형태소 분석\n",
    "from konlpy.tag import Okt, Hannanum, Kkma, Mecab, Komoran\n",
    "# 형태소 벡터를 생성하기 위한 라이브러리\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 형태소 벡터를 학습 벡터로 변환한다.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형태소 추출 함수\n",
    "- stem : True면 원형 어간으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# konlpy 라이브러리로 텍스트 데이터에서 형태소를 추출한다.\n",
    "def get_pos (x) :\n",
    "    tagger = Okt()\n",
    "    #pos = tagger.pos(x)\n",
    "    pos = tagger.pos(x, norm = True, stem = True)\n",
    "    \n",
    "    # 단어와 품사를 합쳐서 하나의 단어로 만들어준다.\n",
    "    result = []\n",
    "    \n",
    "    # 형태소의 수만큼 반복한다.\n",
    "    # 조사인 것과 명사인 것이 같을 수 있기 때문에 구분해준다.\n",
    "    # 형태소 벡터를 만들때 추후 사용\n",
    "    for a1 in pos :\n",
    "        result.append(f'{a1[0]}/{a1[1]}')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kurly['tokens'] = data_kurly['fixed_ReviewText'].apply(lambda x:get_pos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "맞춤법 교정/토큰화 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kurly.to_csv(\"C:/Users/NT550-048/Desktop/잇더/data/data_kurly_tokens.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
